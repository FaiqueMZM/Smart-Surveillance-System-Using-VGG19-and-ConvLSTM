{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc51cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "# Define the ConvLSTM model\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h0, c0 = hidden\n",
    "        out, _ = self.conv_lstm(x, (h0, c0))\n",
    "        return out[:, -1]\n",
    "\n",
    "# Load pre-trained VGG19 model\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "vgg19_features = vgg19.features\n",
    "\n",
    "\n",
    "# Freeze the parameters in VGG19\n",
    "for param in vgg19_features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Combine VGG19 and ConvLSTM\n",
    "class ViolenceDetectionModel(nn.Module):\n",
    "    def __init__(self, vgg_features, hidden_dim, num_layers, num_classes):\n",
    "        super(ViolenceDetectionModel, self).__init__()\n",
    "        self.vgg_features = vgg_features\n",
    "        self.conv_lstm = ConvLSTM(512, hidden_dim, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.vgg_features(x)\n",
    "        features = torch.reshape(features, (features.size(0), -1, features.size(1)))\n",
    "        h0 = torch.zeros(self.conv_lstm.num_layers, features.size(0), self.conv_lstm.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.conv_lstm.num_layers, features.size(0), self.conv_lstm.hidden_dim).to(x.device)\n",
    "        convlstm_out = self.conv_lstm(features, (h0, c0))  # Pass the hidden tuple\n",
    "        out = self.fc(convlstm_out)\n",
    "        return out\n",
    "\n",
    "# Set hyperparameters\n",
    "input_dim = 512  # Dimensionality of input features from VGG16\n",
    "hidden_dim = 128  # Hidden dimension of ConvLSTM\n",
    "num_layers = 1  # Number of ConvLSTM layers\n",
    "num_classes = 2  # Number of output classes (violence, non-violence)\n",
    "\n",
    "# Instantiate the model\n",
    "model = ViolenceDetectionModel(vgg19_features, hidden_dim, num_layers, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('violence_detection_model_v2.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Tkinter GUI Application\n",
    "class Application(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Violence Detection System\")\n",
    "        self.geometry(\"800x400\")\n",
    "\n",
    "        self.header_label = tk.Label(self, text=\"Violence Detection System\", font=(\"Arial\", 20, \"bold\"))\n",
    "        self.header_label.pack(pady=10)\n",
    "\n",
    "        self.instructions = [\n",
    "            \"Instructions:\",\n",
    "            \"1. Select a video file to upload\",\n",
    "            \"2. Supported file formats: .avi, .mp4\",\n",
    "            \"3. Click the 'Upload' button to start the detection\",\n",
    "            \"System will analyze the video and start the process\",\n",
    "            \"This may take some time....\"\n",
    "        ]\n",
    "\n",
    "        for instruction in self.instructions:\n",
    "            instruction_label = tk.Label(self, text=instruction, font=(\"Arial\", 12))\n",
    "            instruction_label.pack(pady=5)\n",
    "\n",
    "        self.upload_button = tk.Button(self, text=\"Upload\", command=self.upload_video)\n",
    "        self.upload_button.pack(pady=10)\n",
    "\n",
    "        self.result_label = tk.Label(self, text=\"\", font=(\"Arial\", 12))\n",
    "        self.result_label.pack(pady=10)\n",
    "\n",
    "    def upload_video(self):\n",
    "        self.result_label.configure(text=\"\")  # Clear previous results\n",
    "        filetypes = ((\"Video Files\", \"*.avi;*.mp4\"), (\"All Files\", \"*.*\"))\n",
    "        filepath = filedialog.askopenfilename(filetypes=filetypes)\n",
    "        if filepath:\n",
    "            self.detect_violence(filepath)\n",
    "\n",
    "    def detect_violence(self, filepath):\n",
    "        threading.Thread(target=self.process_video, args=(filepath,), daemon=True).start()\n",
    "\n",
    "    def process_video(self, filepath):\n",
    "        video = cv2.VideoCapture(filepath)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = frame.astype(np.float32) / 255.0\n",
    "            frame = torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0)\n",
    "            frames.append(frame)\n",
    "        video.release()\n",
    "        frames = torch.cat(frames, dim=0)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(frames)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        predicted_label = 1 if torch.any(predicted_labels == 1) else 0\n",
    "        if predicted_label == 1:\n",
    "            result = \"Violence detected.\"\n",
    "        else:\n",
    "            result = \"No violence detected.\"\n",
    "        self.display_result(result)\n",
    "\n",
    "    def display_result(self, result):\n",
    "        self.result_label.configure(text=result)\n",
    "\n",
    "\n",
    "# Run the application\n",
    "app = Application()\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83700958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
